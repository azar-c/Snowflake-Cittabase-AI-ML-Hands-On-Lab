{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9eb39a-9616-4f56-966a-a364155157b4",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "### Setting Up the Database and Stage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "-- Create Stage for Analyst\n",
    "\n",
    "USE  DATABASE CHATBOT_WORKSHOP_DB;\n",
    "\n",
    "\n",
    "USE CHATBOT_WORKSHOP_DB;\n",
    "\n",
    "CREATE OR REPLACE STAGE DOCS ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );\n",
    "\n",
    "\n",
    "-- Create External Stage \n",
    "CREATE OR REPLACE STAGE CORTEX_SEARCH_EXT_STG\n",
    "url = 's3://holworkshopbucket/Cortex-Search/'\n",
    "file_format = (type = csv);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cad000-d77a-4504-a9c8-fbf31b1a72bd",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "### Copy the Source PDF File into Docs Stage from the Cortex Search External Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3416f33b-b4eb-4c03-b8b8-18e2c3fba57b",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "COPY FILES INTO @DOCS FROM @CORTEX_SEARCH_EXT_STG;\n",
    "\n",
    "LS @DOCS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc224b-f4fa-4a45-ac90-c094b83caf0b",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "### Creating a python function to chunk the pdf document into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54610cf3-a5bf-4b7f-a2a8-495046b351ce",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "cell7"
   },
   "outputs": [],
   "source": [
    "create or replace function text_chunker(pdf_text string)\n",
    "returns table (chunk varchar)\n",
    "language python\n",
    "runtime_version = '3.9'\n",
    "handler = 'text_chunker'\n",
    "packages = ('snowflake-snowpark-python', 'langchain')\n",
    "as\n",
    "$$\n",
    "from snowflake.snowpark.types import StringType, StructField, StructType\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import pandas as pd\n",
    "\n",
    "class text_chunker:\n",
    "\n",
    "    def process(self, pdf_text: str):\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size = 1512, # Adjust this as you see fit\n",
    "            chunk_overlap  = 256, # This enables text have some form of overlap. Useful for keeping chunks contextual\n",
    "            length_function = len\n",
    "        )\n",
    "    \n",
    "        chunks = text_splitter.split_text(pdf_text)\n",
    "        df = pd.DataFrame(chunks, columns=['chunks'])\n",
    "        \n",
    "        yield from df.itertuples(index=False, name=None)\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3235f0c-4244-49e8-a48a-27b794bcf714",
   "metadata": {
    "collapsed": false,
    "name": "cell13"
   },
   "source": [
    "### Listing the file in the docs stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ae2b3d-d42e-4f59-a688-1b43d5fdd3c2",
   "metadata": {
    "language": "sql",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "ls @docs;\n",
    "\n",
    "ALTER STAGE DOCS REFRESH;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0cbd77-6a73-40af-a4a5-e159f352b5ad",
   "metadata": {
    "collapsed": false,
    "name": "cell14"
   },
   "source": [
    "### Create the table where we are going to store the chunks extracted from the PDF.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27366bc-d0ee-4c49-a9fb-7a646676dfc8",
   "metadata": {
    "language": "sql",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "create or replace TABLE DOCS_CHUNKS_TABLE ( \n",
    "    RELATIVE_PATH VARCHAR(16777216), -- Relative path to the PDF file\n",
    "    SIZE NUMBER(38,0), -- Size of the PDF\n",
    "    FILE_URL VARCHAR(16777216), -- URL for the PDF\n",
    "    SCOPED_FILE_URL VARCHAR(16777216), -- Scoped url (you can choose which one to keep depending on your use case)\n",
    "    CHUNK VARCHAR(16777216), -- Piece of text\n",
    "    CATEGORY VARCHAR(16777216) -- Will hold the document category to enable filtering\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3383b3-0cb6-4b09-bbf9-064caae4a7f0",
   "metadata": {
    "collapsed": false,
    "name": "cell6"
   },
   "source": [
    "### Function SNOWFLAKE.CORTEX.PARSE_DOCUMENT will be used to read the PDF documents directly from the staging area. The text will be passed to the function previously created to split the text into chunks. There is no need to create embeddings as that will be managed automatically by Cortex Search service later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a08ba-7635-4a78-931a-12510645d5c3",
   "metadata": {
    "language": "sql",
    "name": "cell9"
   },
   "outputs": [],
   "source": [
    "insert into docs_chunks_table (relative_path, size, file_url,\n",
    "                            scoped_file_url, chunk)\n",
    "\n",
    "    select relative_path, \n",
    "            size,\n",
    "            file_url, \n",
    "            build_scoped_file_url(@docs, relative_path) as scoped_file_url,\n",
    "            func.chunk as chunk\n",
    "    from \n",
    "        directory(@docs),\n",
    "        TABLE(text_chunker (TO_VARCHAR(SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@docs, relative_path, {'mode': 'LAYOUT'})))) as func;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786c8194-2d02-46a9-a083-d6d3be3e780b",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "select * from docs_chunks_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b5b476-74c9-4d33-9a6a-c93c75179f6b",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "### Creating a temp table to load the category of each document using the COMPLETE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca98fcd-ab08-4da7-9e4f-9979c1f298e4",
   "metadata": {
    "language": "sql",
    "name": "cell15"
   },
   "outputs": [],
   "source": [
    "CREATE\n",
    "OR REPLACE TEMPORARY TABLE docs_categories AS WITH unique_documents AS (\n",
    "  SELECT\n",
    "    DISTINCT relative_path\n",
    "  FROM\n",
    "    docs_chunks_table\n",
    "),\n",
    "docs_category_cte AS (\n",
    "  SELECT\n",
    "    relative_path,\n",
    "    TRIM(snowflake.cortex.COMPLETE (\n",
    "      'llama3-70b',\n",
    "      'Given the name of the file between <file> and </file> determine if it is related to banking services or customer support or tech support.\n",
    "       Very strictly, Use only one word <file> ' || relative_path || '</file>'\n",
    "    ), '\\n') AS category\n",
    "  FROM\n",
    "    unique_documents\n",
    ")\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  docs_category_cte;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a5c0e2-024f-441d-bc2c-a2cd0f79403d",
   "metadata": {
    "collapsed": false,
    "name": "cell17"
   },
   "source": [
    "### Update the Chunks Table with the  identified category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece645c3-4c61-45e1-8f27-25d5f8bbf382",
   "metadata": {
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "update docs_chunks_table \n",
    "  SET category = docs_categories.category\n",
    "  from docs_categories\n",
    "  where  docs_chunks_table.relative_path = docs_categories.relative_path;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24e1f78-020e-443e-abf7-67df104cfaba",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "### Verify the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e00845-2324-48d6-ac2c-cfe942306581",
   "metadata": {
    "language": "sql",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "select * from docs_categories;\n",
    "select * from docs_chunks_table;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8185d63a-f544-4e46-a311-f319f37cc859",
   "metadata": {
    "collapsed": false,
    "name": "cell21"
   },
   "source": [
    "### Cortex Search is created and enabled on the chunk column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ba2224-d49c-445d-a9c4-51eb4875316f",
   "metadata": {
    "language": "sql",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "create or replace CORTEX SEARCH SERVICE CUSTOMER_SEARCH_SERVICE\n",
    "ON chunk\n",
    "ATTRIBUTES CATEGORY\n",
    "warehouse = COMPUTE_WH\n",
    "TARGET_LAG = '1 minute'\n",
    "as (\n",
    "    select chunk,\n",
    "        relative_path,\n",
    "        file_url,\n",
    "        category\n",
    "    from docs_chunks_table\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "azar.mohammed@cittabase.com",
   "authorId": "7180874423419",
   "authorName": "AZAR",
   "lastEditTime": 1750564987354,
   "notebookId": "2665xtieiay7wb7qdqiz",
   "sessionId": "17e5c1eb-2014-4a97-97d8-d028f9f77aeb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
